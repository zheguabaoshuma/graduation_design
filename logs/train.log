25-03-12 15:26:13.474 - INFO:   name: Diff-IF-mif-train
  phase: train
  gpu_ids: [0]
  path:[
    log: logs
    tb_logger: tb_logger
    results: results
    checkpoint: checkpoint
    resume_state: None
  ]
  datasets:[
    train:[
      dataset: Harvard
      name: train
      dataroot: dataset/My_dataset/train
      batch_size: 2
      num_workers: 2
      use_shuffle: True
      data_len: -1
    ]
    val:[
      dataset: Test_mif
      name: val
      dataroot: dataset/My_dataset/eval
      data_len: -1
    ]
  ]
  model:[
    which_model_G: diffif
    finetune_norm: False
    unet_denoising:[
      in_channel: 3
      out_channel: 1
      inner_channel: 48
      channel_multiplier: [1, 2, 4, 6]
      attn_res: [16]
      res_blocks: 2
      dropout: 0.1
    ]
    unet_refine:[
      in_channel: 1
      out_channel: 1
    ]
    beta_schedule:[
      train:[
        schedule: linear
        n_timestep: 1000
        linear_start: 1e-06
        linear_end: 0.01
      ]
      val:[
        schedule: linear
        n_timestep: 1000
        linear_start: 1e-06
        linear_end: 0.01
      ]
    ]
    diffusion:[
      channels: 3
      conditional: True
    ]
  ]
  train:[
    n_iter: 16000
    val_freq: 2000.0
    save_checkpoint_freq: 2000.0
    print_freq: 100
    optimizer:[
      type: adam
      lr: 0.0001
    ]
  ]

25-03-12 15:26:13.477 - INFO: Dataset [Harvard_Dataset - train] is created.
25-03-12 15:26:13.477 - INFO: Dataset [Harvard_Test_Dataset - val] is created.
25-03-12 15:26:13.477 - INFO: Initial Dataset Finished
25-03-12 15:26:13.619 - INFO: Initialization method [orthogonal]
25-03-12 15:26:14.110 - INFO: Network G structure: GaussianDiffusion, with parameters: 23,736,399
25-03-12 15:26:14.110 - INFO: GaussianDiffusion(
  (denoise_fn): UNet(
    (noise_level_mlp): Sequential(
      (0): PositionalEncoding()
      (1): Linear(in_features=48, out_features=192, bias=True)
      (2): Swish()
      (3): Linear(in_features=192, out_features=48, bias=True)
    )
    (downs): ModuleList(
      (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1-2): 2 x ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=48, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 48, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 48, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Identity()
        )
      )
      (3): Downsample(
        (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
      (4): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=96, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 48, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 96, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (5): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=96, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 96, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 96, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Identity()
        )
      )
      (6): Downsample(
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
      (7): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=192, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 96, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 192, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (8): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=192, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 192, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 192, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Identity()
        )
      )
      (9): Downsample(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
      (10): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=288, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 192, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(192, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 288, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Conv2d(192, 288, kernel_size=(1, 1), stride=(1, 1))
        )
        (attn): SelfAttention(
          (norm): GroupNorm(24, 288, eps=1e-05, affine=True)
          (qkv): Conv2d(288, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (out): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (11): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=288, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 288, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 288, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Identity()
        )
        (attn): SelfAttention(
          (norm): GroupNorm(24, 288, eps=1e-05, affine=True)
          (qkv): Conv2d(288, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (out): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (mid): ModuleList(
      (0): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=288, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 288, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 288, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Identity()
        )
        (attn): SelfAttention(
          (norm): GroupNorm(24, 288, eps=1e-05, affine=True)
          (qkv): Conv2d(288, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (out): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (1): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=288, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 288, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 288, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Identity()
        )
      )
    )
    (ups): ModuleList(
      (0-1): 2 x ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=288, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 576, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(576, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 288, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Conv2d(576, 288, kernel_size=(1, 1), stride=(1, 1))
        )
        (attn): SelfAttention(
          (norm): GroupNorm(24, 288, eps=1e-05, affine=True)
          (qkv): Conv2d(288, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (out): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (2): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=288, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 480, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(480, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 288, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Conv2d(480, 288, kernel_size=(1, 1), stride=(1, 1))
        )
        (attn): SelfAttention(
          (norm): GroupNorm(24, 288, eps=1e-05, affine=True)
          (qkv): Conv2d(288, 864, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (out): Conv2d(288, 288, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (3): Upsample(
        (up): Upsample(scale_factor=2.0, mode='nearest')
        (conv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (4): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=192, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 480, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(480, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 192, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (5): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=192, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 384, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 192, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (6): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=192, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 288, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(288, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 192, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (7): Upsample(
        (up): Upsample(scale_factor=2.0, mode='nearest')
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (8): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=96, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 288, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(288, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 96, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (9): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=96, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 192, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 96, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (10): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=96, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 144, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(144, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 96, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Conv2d(144, 96, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (11): Upsample(
        (up): Upsample(scale_factor=2.0, mode='nearest')
        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (12): ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=48, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 144, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 48, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (13-14): 2 x ResnetBlocWithAttn(
        (res_block): ResnetBlock(
          (noise_func): FeatureWiseAffine(
            (noise_func): Sequential(
              (0): Linear(in_features=48, out_features=48, bias=True)
            )
          )
          (block1): Block(
            (block): Sequential(
              (0): GroupNorm(24, 96, eps=1e-05, affine=True)
              (1): Swish()
              (2): Identity()
              (3): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (block2): Block(
            (block): Sequential(
              (0): GroupNorm(24, 48, eps=1e-05, affine=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            )
          )
          (res_conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
    (final_conv): Block(
      (block): Sequential(
        (0): GroupNorm(24, 48, eps=1e-05, affine=True)
        (1): Swish()
        (2): Identity()
        (3): Conv2d(48, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (refinement_fn): Restormer_fn(
    (noise_level_mlp): Sequential(
      (0): PositionalEncoding()
      (1): Linear(in_features=36, out_features=144, bias=True)
      (2): Swish()
      (3): Linear(in_features=144, out_features=36, bias=True)
    )
    (patch_embed): OverlapPatchEmbed(
      (proj): Conv2d(1, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (patch_embed_refine): OverlapPatchEmbed(
      (proj): Conv2d(2, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
    (encoder_level1): Sequential(
      (0): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (1): FeatureWiseAffine(
        (noise_func): Sequential(
          (0): Linear(in_features=36, out_features=36, bias=True)
        )
      )
      (2): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (3): FeatureWiseAffine(
        (noise_func): Sequential(
          (0): Linear(in_features=36, out_features=36, bias=True)
        )
      )
    )
    (encoder_level1_refine): Sequential(
      (0): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (1): FeatureWiseAffine(
        (noise_func): Sequential(
          (0): Linear(in_features=36, out_features=36, bias=True)
        )
      )
      (2): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (3): FeatureWiseAffine(
        (noise_func): Sequential(
          (0): Linear(in_features=36, out_features=36, bias=True)
        )
      )
    )
    (reduce_chan_level1_refine): Conv2d(72, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (encoder_level2): Sequential(
      (0): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (1): FeatureWiseAffine(
        (noise_func): Sequential(
          (0): Linear(in_features=36, out_features=36, bias=True)
        )
      )
      (2): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (3): FeatureWiseAffine(
        (noise_func): Sequential(
          (0): Linear(in_features=36, out_features=36, bias=True)
        )
      )
    )
    (encoder_level2_refine): Sequential(
      (0): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (1): FeatureWiseAffine(
        (noise_func): Sequential(
          (0): Linear(in_features=36, out_features=36, bias=True)
        )
      )
      (2): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (3): FeatureWiseAffine(
        (noise_func): Sequential(
          (0): Linear(in_features=36, out_features=36, bias=True)
        )
      )
    )
    (reduce_chan_level2_refine): Conv2d(72, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (decoder_level2): Sequential(
      (0): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (1): FeatureWiseAffine(
        (noise_func): Sequential(
          (0): Linear(in_features=36, out_features=36, bias=True)
        )
      )
      (2): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (3): FeatureWiseAffine(
        (noise_func): Sequential(
          (0): Linear(in_features=36, out_features=36, bias=True)
        )
      )
    )
    (reduce_chan_level1): Conv2d(72, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (decoder_level1): Sequential(
      (0): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (1): FeatureWiseAffine(
        (noise_func): Sequential(
          (0): Linear(in_features=36, out_features=36, bias=True)
        )
      )
      (2): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (3): FeatureWiseAffine(
        (noise_func): Sequential(
          (0): Linear(in_features=36, out_features=36, bias=True)
        )
      )
    )
    (reduce_chan_level_out): Conv2d(72, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (refinement): Sequential(
      (0): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
      (1): TransformerBlock(
        (norm1): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (attn): Attention(
          (qkv): Conv2d(36, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (qkv_dwconv): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=108, bias=False)
          (project_out): Conv2d(36, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
        (norm2): LayerNorm(
          (body): WithBias_LayerNorm()
        )
        (ffn): FeedForward(
          (project_in): Conv2d(36, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (dwconv): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (project_out): Conv2d(95, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)
        )
      )
    )
    (output): Conv2d(36, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (loss_func): L1Loss()
  (grad_loss): Grad_loss()
  (ssim_loss): SSIM_loss()
)
25-03-12 15:26:14.110 - INFO: Initial Model Finished
25-03-12 15:26:39.410 - INFO: <epoch:  2, iter:     100> l_pix: 5.6965e+00 l_eps: 1.1588e+00 l_max: 2.6854e-01 l_grad: 1.9830e+00 l_ssim: 1.2139e+00 l_x0: 1.0724e+00 
25-03-12 15:26:58.614 - INFO: <epoch:  3, iter:     200> l_pix: 5.7718e+00 l_eps: 1.3080e+00 l_max: 3.9099e-01 l_grad: 1.8454e+00 l_ssim: 1.0768e+00 l_x0: 1.1506e+00 
25-03-12 15:27:17.866 - INFO: <epoch:  4, iter:     300> l_pix: 4.4201e+00 l_eps: 8.3694e-01 l_max: 1.9530e-01 l_grad: 1.4149e+00 l_ssim: 9.1683e-01 l_x0: 1.0560e+00 
25-03-12 15:27:37.107 - INFO: <epoch:  5, iter:     400> l_pix: 7.1950e+00 l_eps: 2.0967e+00 l_max: 3.9898e-01 l_grad: 2.4202e+00 l_ssim: 1.3384e+00 l_x0: 9.4066e-01 
25-03-12 15:27:56.425 - INFO: <epoch:  7, iter:     500> l_pix: 4.8995e+00 l_eps: 9.0761e-01 l_max: 5.1465e-01 l_grad: 1.4934e+00 l_ssim: 9.8077e-01 l_x0: 1.0031e+00 
25-03-12 15:28:15.690 - INFO: <epoch:  8, iter:     600> l_pix: 4.8878e+00 l_eps: 1.0797e+00 l_max: 2.4715e-01 l_grad: 1.3969e+00 l_ssim: 9.3871e-01 l_x0: 1.2253e+00 
25-03-12 15:28:34.985 - INFO: <epoch:  9, iter:     700> l_pix: 5.1758e+00 l_eps: 7.6135e-01 l_max: 2.3254e-01 l_grad: 1.7890e+00 l_ssim: 1.0160e+00 l_x0: 1.3769e+00 
25-03-12 15:28:54.231 - INFO: <epoch: 10, iter:     800> l_pix: 8.6474e+00 l_eps: 5.3474e+00 l_max: 2.5354e-01 l_grad: 1.3581e+00 l_ssim: 8.0984e-01 l_x0: 8.7856e-01 
25-03-12 15:29:13.606 - INFO: <epoch: 12, iter:     900> l_pix: 1.0983e+01 l_eps: 6.8519e+00 l_max: 2.4493e-01 l_grad: 1.3416e+00 l_ssim: 1.1392e+00 l_x0: 1.4055e+00 
25-03-12 15:29:32.880 - INFO: <epoch: 13, iter:   1,000> l_pix: 5.4101e+00 l_eps: 9.2285e-01 l_max: 3.7735e-01 l_grad: 1.9676e+00 l_ssim: 1.1043e+00 l_x0: 1.0380e+00 
25-03-12 15:29:52.173 - INFO: <epoch: 14, iter:   1,100> l_pix: 5.4510e+00 l_eps: 1.0362e+00 l_max: 3.7891e-01 l_grad: 2.0088e+00 l_ssim: 8.2840e-01 l_x0: 1.1987e+00 
25-03-12 15:30:11.483 - INFO: <epoch: 15, iter:   1,200> l_pix: 5.4222e+00 l_eps: 8.5090e-01 l_max: 6.1316e-01 l_grad: 1.6425e+00 l_ssim: 1.3592e+00 l_x0: 9.5653e-01 
25-03-12 15:30:30.939 - INFO: <epoch: 17, iter:   1,300> l_pix: 4.5758e+00 l_eps: 5.7285e-01 l_max: 2.6410e-01 l_grad: 1.5623e+00 l_ssim: 9.2779e-01 l_x0: 1.2487e+00 
25-03-12 15:30:50.271 - INFO: <epoch: 18, iter:   1,400> l_pix: 4.6074e+00 l_eps: 5.9590e-01 l_max: 3.2933e-01 l_grad: 1.6319e+00 l_ssim: 1.0265e+00 l_x0: 1.0238e+00 
25-03-12 15:31:09.615 - INFO: <epoch: 19, iter:   1,500> l_pix: 9.4211e+00 l_eps: 4.9323e+00 l_max: 4.2642e-01 l_grad: 1.4898e+00 l_ssim: 1.1455e+00 l_x0: 1.4270e+00 
25-03-12 15:31:28.968 - INFO: <epoch: 20, iter:   1,600> l_pix: 8.6996e+00 l_eps: 4.3265e+00 l_max: 3.1988e-01 l_grad: 1.9801e+00 l_ssim: 8.1748e-01 l_x0: 1.2556e+00 
25-03-12 15:31:48.408 - INFO: <epoch: 22, iter:   1,700> l_pix: 6.1471e+00 l_eps: 1.8526e+00 l_max: 3.1005e-01 l_grad: 1.9755e+00 l_ssim: 9.9657e-01 l_x0: 1.0124e+00 
25-03-12 15:32:07.812 - INFO: <epoch: 23, iter:   1,800> l_pix: 5.3973e+00 l_eps: 1.4200e+00 l_max: 2.1325e-01 l_grad: 1.6231e+00 l_ssim: 9.8242e-01 l_x0: 1.1584e+00 
25-03-12 15:32:27.161 - INFO: <epoch: 24, iter:   1,900> l_pix: 4.4210e+00 l_eps: 5.6125e-01 l_max: 2.3235e-01 l_grad: 1.6276e+00 l_ssim: 1.0175e+00 l_x0: 9.8228e-01 
25-03-12 15:32:46.497 - INFO: <epoch: 25, iter:   2,000> l_pix: 4.1094e+00 l_eps: 6.8073e-01 l_max: 2.3292e-01 l_grad: 1.3095e+00 l_ssim: 8.9743e-01 l_x0: 9.8876e-01 
25-03-12 15:32:56.817 - INFO: <epoch: 25, iter:   2,000 Evaluation.>
25-03-12 15:32:56.817 - INFO: Saving models and training states.
25-03-12 15:32:57.140 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 15:32:57.140 - INFO: Saving models and training states.
25-03-12 15:32:57.661 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 15:33:16.956 - INFO: <epoch: 27, iter:   2,100> l_pix: 6.2304e+00 l_eps: 1.9295e+00 l_max: 3.3740e-01 l_grad: 1.3919e+00 l_ssim: 1.1429e+00 l_x0: 1.4286e+00 
25-03-12 15:33:36.264 - INFO: <epoch: 28, iter:   2,200> l_pix: 5.1580e+00 l_eps: 1.2205e+00 l_max: 3.0138e-01 l_grad: 1.7020e+00 l_ssim: 8.5446e-01 l_x0: 1.0796e+00 
25-03-12 15:33:55.620 - INFO: <epoch: 29, iter:   2,300> l_pix: 4.5802e+00 l_eps: 1.1080e+00 l_max: 2.5112e-01 l_grad: 1.2810e+00 l_ssim: 7.5031e-01 l_x0: 1.1898e+00 
25-03-12 15:34:14.888 - INFO: <epoch: 30, iter:   2,400> l_pix: 4.9436e+00 l_eps: 8.3261e-01 l_max: 3.9973e-01 l_grad: 1.2469e+00 l_ssim: 1.0868e+00 l_x0: 1.3776e+00 
25-03-12 15:34:34.275 - INFO: <epoch: 32, iter:   2,500> l_pix: 6.4089e+00 l_eps: 2.2275e+00 l_max: 4.2602e-01 l_grad: 1.3500e+00 l_ssim: 1.2056e+00 l_x0: 1.1998e+00 
25-03-12 15:34:53.566 - INFO: <epoch: 33, iter:   2,600> l_pix: 5.5589e+00 l_eps: 8.7774e-01 l_max: 3.4490e-01 l_grad: 2.0862e+00 l_ssim: 1.0457e+00 l_x0: 1.2044e+00 
25-03-12 15:35:12.879 - INFO: <epoch: 34, iter:   2,700> l_pix: 4.6066e+00 l_eps: 8.2762e-01 l_max: 2.2652e-01 l_grad: 1.4948e+00 l_ssim: 8.0055e-01 l_x0: 1.2571e+00 
25-03-12 15:35:32.164 - INFO: <epoch: 35, iter:   2,800> l_pix: 4.1430e+00 l_eps: 3.9876e-01 l_max: 2.6561e-01 l_grad: 1.1679e+00 l_ssim: 1.0095e+00 l_x0: 1.3012e+00 
25-03-12 15:35:51.608 - INFO: <epoch: 37, iter:   2,900> l_pix: 4.9531e+00 l_eps: 9.7991e-01 l_max: 2.6286e-01 l_grad: 1.6969e+00 l_ssim: 9.7229e-01 l_x0: 1.0411e+00 
25-03-12 15:36:10.900 - INFO: <epoch: 38, iter:   3,000> l_pix: 5.4953e+00 l_eps: 1.6725e+00 l_max: 2.3609e-01 l_grad: 1.6577e+00 l_ssim: 9.2783e-01 l_x0: 1.0012e+00 
25-03-12 15:36:30.229 - INFO: <epoch: 39, iter:   3,100> l_pix: 5.4360e+00 l_eps: 1.0591e+00 l_max: 3.1612e-01 l_grad: 2.0410e+00 l_ssim: 9.6806e-01 l_x0: 1.0517e+00 
25-03-12 15:36:49.504 - INFO: <epoch: 40, iter:   3,200> l_pix: 5.0088e+00 l_eps: 7.5194e-01 l_max: 4.9483e-01 l_grad: 1.5774e+00 l_ssim: 1.0218e+00 l_x0: 1.1628e+00 
25-03-12 15:37:08.895 - INFO: <epoch: 42, iter:   3,300> l_pix: 4.8949e+00 l_eps: 4.7013e-01 l_max: 2.9470e-01 l_grad: 1.8160e+00 l_ssim: 1.0389e+00 l_x0: 1.2752e+00 
25-03-12 15:37:28.200 - INFO: <epoch: 43, iter:   3,400> l_pix: 3.3615e+00 l_eps: 4.4828e-01 l_max: 1.9507e-01 l_grad: 1.1301e+00 l_ssim: 7.5892e-01 l_x0: 8.2912e-01 
25-03-12 15:37:47.550 - INFO: <epoch: 44, iter:   3,500> l_pix: 4.8114e+00 l_eps: 6.3382e-01 l_max: 2.7846e-01 l_grad: 1.6643e+00 l_ssim: 9.1855e-01 l_x0: 1.3163e+00 
25-03-12 15:38:06.821 - INFO: <epoch: 45, iter:   3,600> l_pix: 4.9748e+00 l_eps: 4.7806e-01 l_max: 2.6303e-01 l_grad: 1.8966e+00 l_ssim: 1.0150e+00 l_x0: 1.3221e+00 
25-03-12 15:38:26.179 - INFO: <epoch: 47, iter:   3,700> l_pix: 5.0842e+00 l_eps: 1.2980e+00 l_max: 2.2738e-01 l_grad: 1.3222e+00 l_ssim: 8.5851e-01 l_x0: 1.3782e+00 
25-03-12 15:38:45.458 - INFO: <epoch: 48, iter:   3,800> l_pix: 6.2765e+00 l_eps: 2.5664e+00 l_max: 3.0932e-01 l_grad: 1.4374e+00 l_ssim: 8.6607e-01 l_x0: 1.0974e+00 
25-03-12 15:39:04.734 - INFO: <epoch: 49, iter:   3,900> l_pix: 5.2481e+00 l_eps: 1.1312e+00 l_max: 2.6856e-01 l_grad: 1.8099e+00 l_ssim: 9.5522e-01 l_x0: 1.0832e+00 
25-03-12 15:39:24.086 - INFO: <epoch: 50, iter:   4,000> l_pix: 6.6554e+00 l_eps: 3.0044e+00 l_max: 2.2188e-01 l_grad: 1.5013e+00 l_ssim: 9.7178e-01 l_x0: 9.5607e-01 
25-03-12 15:39:32.684 - INFO: <epoch: 50, iter:   4,000 Evaluation.>
25-03-12 15:39:32.684 - INFO: Saving models and training states.
25-03-12 15:39:33.238 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 15:39:33.238 - INFO: Saving models and training states.
25-03-12 15:39:33.735 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 15:39:53.078 - INFO: <epoch: 52, iter:   4,100> l_pix: 6.5908e+00 l_eps: 3.0719e+00 l_max: 2.0830e-01 l_grad: 1.4392e+00 l_ssim: 8.3977e-01 l_x0: 1.0317e+00 
25-03-12 15:40:12.345 - INFO: <epoch: 53, iter:   4,200> l_pix: 7.8998e+00 l_eps: 3.6394e+00 l_max: 4.7173e-01 l_grad: 1.4582e+00 l_ssim: 1.1826e+00 l_x0: 1.1479e+00 
25-03-12 15:40:31.632 - INFO: <epoch: 54, iter:   4,300> l_pix: 4.7406e+00 l_eps: 3.7649e-01 l_max: 2.7518e-01 l_grad: 1.8370e+00 l_ssim: 1.1253e+00 l_x0: 1.1267e+00 
25-03-12 15:40:50.910 - INFO: <epoch: 55, iter:   4,400> l_pix: 4.7235e+00 l_eps: 4.6531e-01 l_max: 3.0176e-01 l_grad: 1.7973e+00 l_ssim: 8.5306e-01 l_x0: 1.3061e+00 
25-03-12 15:41:10.300 - INFO: <epoch: 57, iter:   4,500> l_pix: 4.6390e+00 l_eps: 8.0618e-01 l_max: 2.6648e-01 l_grad: 1.3817e+00 l_ssim: 8.2048e-01 l_x0: 1.3641e+00 
25-03-12 15:41:29.572 - INFO: <epoch: 58, iter:   4,600> l_pix: 5.2185e+00 l_eps: 1.3521e+00 l_max: 2.4060e-01 l_grad: 1.5419e+00 l_ssim: 9.0186e-01 l_x0: 1.1820e+00 
25-03-12 15:41:48.862 - INFO: <epoch: 59, iter:   4,700> l_pix: 7.1100e+00 l_eps: 2.9872e+00 l_max: 2.8314e-01 l_grad: 1.8064e+00 l_ssim: 9.4537e-01 l_x0: 1.0879e+00 
25-03-12 15:42:08.129 - INFO: <epoch: 60, iter:   4,800> l_pix: 4.7207e+00 l_eps: 9.0368e-01 l_max: 3.0369e-01 l_grad: 1.1820e+00 l_ssim: 1.0440e+00 l_x0: 1.2873e+00 
25-03-12 15:42:27.476 - INFO: <epoch: 62, iter:   4,900> l_pix: 4.4988e+00 l_eps: 9.8369e-01 l_max: 2.6234e-01 l_grad: 1.4006e+00 l_ssim: 8.4858e-01 l_x0: 1.0035e+00 
25-03-12 15:42:46.756 - INFO: <epoch: 63, iter:   5,000> l_pix: 4.9691e+00 l_eps: 7.0922e-01 l_max: 3.9274e-01 l_grad: 1.2325e+00 l_ssim: 1.1259e+00 l_x0: 1.5087e+00 
25-03-12 15:43:06.071 - INFO: <epoch: 64, iter:   5,100> l_pix: 4.2841e+00 l_eps: 9.1241e-01 l_max: 2.1904e-01 l_grad: 1.3070e+00 l_ssim: 8.3845e-01 l_x0: 1.0072e+00 
25-03-12 15:43:25.346 - INFO: <epoch: 65, iter:   5,200> l_pix: 4.6358e+00 l_eps: 3.9532e-01 l_max: 3.6279e-01 l_grad: 1.8503e+00 l_ssim: 1.0853e+00 l_x0: 9.4203e-01 
25-03-12 15:43:44.725 - INFO: <epoch: 67, iter:   5,300> l_pix: 5.1511e+00 l_eps: 4.4395e-01 l_max: 3.8542e-01 l_grad: 1.8873e+00 l_ssim: 1.0135e+00 l_x0: 1.4209e+00 
25-03-12 15:44:04.021 - INFO: <epoch: 68, iter:   5,400> l_pix: 4.4048e+00 l_eps: 3.9018e-01 l_max: 2.9590e-01 l_grad: 1.6510e+00 l_ssim: 1.0900e+00 l_x0: 9.7779e-01 
25-03-12 15:44:23.288 - INFO: <epoch: 69, iter:   5,500> l_pix: 4.2526e+00 l_eps: 4.1761e-01 l_max: 3.7282e-01 l_grad: 1.3917e+00 l_ssim: 1.1773e+00 l_x0: 8.9315e-01 
25-03-12 15:44:42.535 - INFO: <epoch: 70, iter:   5,600> l_pix: 3.5580e+00 l_eps: 7.9306e-01 l_max: 1.5218e-01 l_grad: 8.5399e-01 l_ssim: 7.1579e-01 l_x0: 1.0430e+00 
25-03-12 15:45:01.935 - INFO: <epoch: 72, iter:   5,700> l_pix: 3.2255e+00 l_eps: 4.8805e-01 l_max: 1.3171e-01 l_grad: 9.7989e-01 l_ssim: 7.9188e-01 l_x0: 8.3396e-01 
25-03-12 15:45:21.198 - INFO: <epoch: 73, iter:   5,800> l_pix: 4.3841e+00 l_eps: 9.8488e-01 l_max: 2.1828e-01 l_grad: 9.9998e-01 l_ssim: 9.8015e-01 l_x0: 1.2008e+00 
25-03-12 15:45:40.459 - INFO: <epoch: 74, iter:   5,900> l_pix: 6.2648e+00 l_eps: 2.1201e+00 l_max: 4.6111e-01 l_grad: 1.5958e+00 l_ssim: 9.8256e-01 l_x0: 1.1052e+00 
25-03-12 15:45:59.713 - INFO: <epoch: 75, iter:   6,000> l_pix: 3.9755e+00 l_eps: 5.5526e-01 l_max: 4.8808e-01 l_grad: 1.2251e+00 l_ssim: 8.7979e-01 l_x0: 8.2732e-01 
25-03-12 15:46:08.251 - INFO: <epoch: 75, iter:   6,000 Evaluation.>
25-03-12 15:46:08.251 - INFO: Saving models and training states.
25-03-12 15:46:08.802 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 15:46:08.803 - INFO: Saving models and training states.
25-03-12 15:46:09.346 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 15:46:28.754 - INFO: <epoch: 77, iter:   6,100> l_pix: 3.7627e+00 l_eps: 4.4050e-01 l_max: 2.2088e-01 l_grad: 9.1309e-01 l_ssim: 9.2240e-01 l_x0: 1.2658e+00 
25-03-12 15:46:48.034 - INFO: <epoch: 78, iter:   6,200> l_pix: 4.7241e+00 l_eps: 1.2357e+00 l_max: 2.2963e-01 l_grad: 1.2718e+00 l_ssim: 9.0465e-01 l_x0: 1.0824e+00 
25-03-12 15:47:07.328 - INFO: <epoch: 79, iter:   6,300> l_pix: 4.5900e+00 l_eps: 9.8417e-01 l_max: 3.1487e-01 l_grad: 1.2410e+00 l_ssim: 9.1140e-01 l_x0: 1.1385e+00 
25-03-12 15:47:26.610 - INFO: <epoch: 80, iter:   6,400> l_pix: 4.2554e+00 l_eps: 2.8398e-01 l_max: 3.6784e-01 l_grad: 1.1627e+00 l_ssim: 1.1260e+00 l_x0: 1.3148e+00 
25-03-12 15:47:45.973 - INFO: <epoch: 82, iter:   6,500> l_pix: 4.1905e+00 l_eps: 6.5999e-01 l_max: 2.3428e-01 l_grad: 1.3060e+00 l_ssim: 8.9042e-01 l_x0: 1.0999e+00 
25-03-12 15:48:05.256 - INFO: <epoch: 83, iter:   6,600> l_pix: 5.7142e+00 l_eps: 2.2545e+00 l_max: 2.8789e-01 l_grad: 7.9095e-01 l_ssim: 1.0469e+00 l_x0: 1.3340e+00 
25-03-12 15:48:24.576 - INFO: <epoch: 84, iter:   6,700> l_pix: 4.2090e+00 l_eps: 7.6558e-01 l_max: 2.4797e-01 l_grad: 1.3603e+00 l_ssim: 6.8241e-01 l_x0: 1.1527e+00 
25-03-12 15:48:43.854 - INFO: <epoch: 85, iter:   6,800> l_pix: 4.4273e+00 l_eps: 3.7084e-01 l_max: 3.2309e-01 l_grad: 1.4248e+00 l_ssim: 1.1556e+00 l_x0: 1.1530e+00 
25-03-12 15:49:03.222 - INFO: <epoch: 87, iter:   6,900> l_pix: 5.1816e+00 l_eps: 1.9494e+00 l_max: 1.9703e-01 l_grad: 1.0877e+00 l_ssim: 9.6981e-01 l_x0: 9.7773e-01 
25-03-12 15:49:22.491 - INFO: <epoch: 88, iter:   7,000> l_pix: 3.3594e+00 l_eps: 3.1158e-01 l_max: 2.2556e-01 l_grad: 7.5105e-01 l_ssim: 7.4367e-01 l_x0: 1.3275e+00 
25-03-12 15:49:41.739 - INFO: <epoch: 89, iter:   7,100> l_pix: 4.3580e+00 l_eps: 5.4693e-01 l_max: 3.3030e-01 l_grad: 1.0968e+00 l_ssim: 1.0096e+00 l_x0: 1.3743e+00 
25-03-12 15:50:01.039 - INFO: <epoch: 90, iter:   7,200> l_pix: 4.8867e+00 l_eps: 5.7764e-01 l_max: 3.3650e-01 l_grad: 1.6445e+00 l_ssim: 9.6427e-01 l_x0: 1.3637e+00 
25-03-12 15:50:20.378 - INFO: <epoch: 92, iter:   7,300> l_pix: 3.8177e+00 l_eps: 6.0818e-01 l_max: 1.9645e-01 l_grad: 1.0108e+00 l_ssim: 8.8905e-01 l_x0: 1.1132e+00 
25-03-12 15:50:39.627 - INFO: <epoch: 93, iter:   7,400> l_pix: 4.3125e+00 l_eps: 9.2085e-01 l_max: 2.2377e-01 l_grad: 1.3066e+00 l_ssim: 8.4319e-01 l_x0: 1.0180e+00 
25-03-12 15:50:58.873 - INFO: <epoch: 94, iter:   7,500> l_pix: 4.8601e+00 l_eps: 7.5293e-01 l_max: 3.1600e-01 l_grad: 1.4818e+00 l_ssim: 9.7676e-01 l_x0: 1.3327e+00 
25-03-12 15:51:18.137 - INFO: <epoch: 95, iter:   7,600> l_pix: 4.7682e+00 l_eps: 1.1791e+00 l_max: 2.3356e-01 l_grad: 9.0102e-01 l_ssim: 1.0688e+00 l_x0: 1.3857e+00 
25-03-12 15:51:37.519 - INFO: <epoch: 97, iter:   7,700> l_pix: 5.3375e+00 l_eps: 1.6470e+00 l_max: 2.8091e-01 l_grad: 1.3343e+00 l_ssim: 9.3158e-01 l_x0: 1.1436e+00 
25-03-12 15:51:56.858 - INFO: <epoch: 98, iter:   7,800> l_pix: 4.4899e+00 l_eps: 9.4520e-01 l_max: 3.2468e-01 l_grad: 1.4419e+00 l_ssim: 9.1126e-01 l_x0: 8.6690e-01 
25-03-12 15:52:16.122 - INFO: <epoch: 99, iter:   7,900> l_pix: 3.6579e+00 l_eps: 4.5243e-01 l_max: 2.1463e-01 l_grad: 1.0218e+00 l_ssim: 9.9369e-01 l_x0: 9.7538e-01 
25-03-12 15:52:35.390 - INFO: <epoch:100, iter:   8,000> l_pix: 2.8899e+00 l_eps: 3.3788e-01 l_max: 2.1509e-01 l_grad: 7.6052e-01 l_ssim: 5.9033e-01 l_x0: 9.8608e-01 
25-03-12 15:52:43.938 - INFO: <epoch:100, iter:   8,000 Evaluation.>
25-03-12 15:52:43.938 - INFO: Saving models and training states.
25-03-12 15:52:44.490 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 15:52:44.491 - INFO: Saving models and training states.
25-03-12 15:52:45.023 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 15:53:04.388 - INFO: <epoch:102, iter:   8,100> l_pix: 4.0527e+00 l_eps: 4.4489e-01 l_max: 2.1911e-01 l_grad: 1.3333e+00 l_ssim: 8.8731e-01 l_x0: 1.1680e+00 
25-03-12 15:53:23.668 - INFO: <epoch:103, iter:   8,200> l_pix: 3.4764e+00 l_eps: 9.2628e-01 l_max: 1.3582e-01 l_grad: 7.1771e-01 l_ssim: 8.0197e-01 l_x0: 8.9464e-01 
25-03-12 15:53:42.964 - INFO: <epoch:104, iter:   8,300> l_pix: 3.5801e+00 l_eps: 3.3919e-01 l_max: 2.7208e-01 l_grad: 1.1587e+00 l_ssim: 8.6542e-01 l_x0: 9.4465e-01 
25-03-12 15:54:02.224 - INFO: <epoch:105, iter:   8,400> l_pix: 4.1652e+00 l_eps: 8.4178e-01 l_max: 2.7799e-01 l_grad: 8.1442e-01 l_ssim: 1.0015e+00 l_x0: 1.2295e+00 
25-03-12 15:54:21.598 - INFO: <epoch:107, iter:   8,500> l_pix: 4.6311e+00 l_eps: 8.8815e-01 l_max: 2.8297e-01 l_grad: 1.0581e+00 l_ssim: 1.0592e+00 l_x0: 1.3427e+00 
25-03-12 15:54:40.909 - INFO: <epoch:108, iter:   8,600> l_pix: 4.2740e+00 l_eps: 3.4908e-01 l_max: 3.2694e-01 l_grad: 1.4613e+00 l_ssim: 1.0017e+00 l_x0: 1.1350e+00 
25-03-12 15:55:00.212 - INFO: <epoch:109, iter:   8,700> l_pix: 4.0414e+00 l_eps: 3.6515e-01 l_max: 3.1049e-01 l_grad: 8.7086e-01 l_ssim: 1.1634e+00 l_x0: 1.3315e+00 
25-03-12 15:55:19.545 - INFO: <epoch:110, iter:   8,800> l_pix: 3.4211e+00 l_eps: 3.9749e-01 l_max: 2.3140e-01 l_grad: 1.1121e+00 l_ssim: 7.7000e-01 l_x0: 9.1011e-01 
25-03-12 15:55:38.904 - INFO: <epoch:112, iter:   8,900> l_pix: 3.8125e+00 l_eps: 4.1781e-01 l_max: 2.4027e-01 l_grad: 1.0376e+00 l_ssim: 9.3834e-01 l_x0: 1.1785e+00 
25-03-12 15:55:58.182 - INFO: <epoch:113, iter:   9,000> l_pix: 4.5691e+00 l_eps: 7.7129e-01 l_max: 2.3429e-01 l_grad: 1.2785e+00 l_ssim: 8.8587e-01 l_x0: 1.3992e+00 
25-03-12 15:56:17.460 - INFO: <epoch:114, iter:   9,100> l_pix: 4.1115e+00 l_eps: 3.8982e-01 l_max: 2.7620e-01 l_grad: 1.3489e+00 l_ssim: 1.0693e+00 l_x0: 1.0273e+00 
25-03-12 15:56:36.718 - INFO: <epoch:115, iter:   9,200> l_pix: 3.9083e+00 l_eps: 5.4698e-01 l_max: 3.0632e-01 l_grad: 1.2071e+00 l_ssim: 9.8144e-01 l_x0: 8.6643e-01 
25-03-12 15:56:56.062 - INFO: <epoch:117, iter:   9,300> l_pix: 3.4288e+00 l_eps: 3.7042e-01 l_max: 2.3056e-01 l_grad: 8.3820e-01 l_ssim: 8.7383e-01 l_x0: 1.1158e+00 
25-03-12 15:57:15.415 - INFO: <epoch:118, iter:   9,400> l_pix: 3.8666e+00 l_eps: 3.5738e-01 l_max: 2.5230e-01 l_grad: 1.0472e+00 l_ssim: 9.4203e-01 l_x0: 1.2677e+00 
25-03-12 15:57:34.672 - INFO: <epoch:119, iter:   9,500> l_pix: 3.8915e+00 l_eps: 9.0826e-01 l_max: 2.5821e-01 l_grad: 8.4252e-01 l_ssim: 9.5624e-01 l_x0: 9.2632e-01 
25-03-12 15:57:53.926 - INFO: <epoch:120, iter:   9,600> l_pix: 3.9938e+00 l_eps: 7.3992e-01 l_max: 2.3660e-01 l_grad: 9.7397e-01 l_ssim: 8.9084e-01 l_x0: 1.1525e+00 
25-03-12 15:58:13.270 - INFO: <epoch:122, iter:   9,700> l_pix: 5.1022e+00 l_eps: 1.3506e+00 l_max: 3.6210e-01 l_grad: 1.3109e+00 l_ssim: 8.7653e-01 l_x0: 1.2021e+00 
25-03-12 15:58:32.529 - INFO: <epoch:123, iter:   9,800> l_pix: 6.1348e+00 l_eps: 2.4031e+00 l_max: 2.7718e-01 l_grad: 1.1786e+00 l_ssim: 9.8920e-01 l_x0: 1.2868e+00 
25-03-12 15:58:51.850 - INFO: <epoch:124, iter:   9,900> l_pix: 5.0734e+00 l_eps: 5.6479e-01 l_max: 4.5358e-01 l_grad: 1.8518e+00 l_ssim: 1.0679e+00 l_x0: 1.1354e+00 
25-03-12 15:59:11.126 - INFO: <epoch:125, iter:  10,000> l_pix: 5.5020e+00 l_eps: 1.4628e+00 l_max: 3.6536e-01 l_grad: 1.2985e+00 l_ssim: 1.2000e+00 l_x0: 1.1753e+00 
25-03-12 15:59:19.689 - INFO: <epoch:125, iter:  10,000 Evaluation.>
25-03-12 15:59:19.689 - INFO: Saving models and training states.
25-03-12 15:59:20.236 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 15:59:20.236 - INFO: Saving models and training states.
25-03-12 15:59:20.756 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 15:59:40.114 - INFO: <epoch:127, iter:  10,100> l_pix: 4.5775e+00 l_eps: 4.2573e-01 l_max: 2.9366e-01 l_grad: 1.4929e+00 l_ssim: 1.0275e+00 l_x0: 1.3377e+00 
25-03-12 15:59:59.381 - INFO: <epoch:128, iter:  10,200> l_pix: 7.4140e+00 l_eps: 3.2576e+00 l_max: 4.1444e-01 l_grad: 1.4360e+00 l_ssim: 8.7808e-01 l_x0: 1.4279e+00 
25-03-12 16:00:18.661 - INFO: <epoch:129, iter:  10,300> l_pix: 4.8636e+00 l_eps: 1.1678e+00 l_max: 2.7479e-01 l_grad: 1.2931e+00 l_ssim: 1.0527e+00 l_x0: 1.0752e+00 
25-03-12 16:00:38.009 - INFO: <epoch:130, iter:  10,400> l_pix: 5.0397e+00 l_eps: 1.7545e+00 l_max: 2.1067e-01 l_grad: 6.4291e-01 l_ssim: 1.0719e+00 l_x0: 1.3597e+00 
25-03-12 16:00:57.359 - INFO: <epoch:132, iter:  10,500> l_pix: 3.9078e+00 l_eps: 8.7674e-01 l_max: 1.9087e-01 l_grad: 8.2332e-01 l_ssim: 8.1679e-01 l_x0: 1.2001e+00 
25-03-12 16:01:16.640 - INFO: <epoch:133, iter:  10,600> l_pix: 3.8291e+00 l_eps: 4.4965e-01 l_max: 3.0999e-01 l_grad: 9.6866e-01 l_ssim: 1.0824e+00 l_x0: 1.0184e+00 
25-03-12 16:01:35.910 - INFO: <epoch:134, iter:  10,700> l_pix: 5.4566e+00 l_eps: 1.6940e+00 l_max: 2.6918e-01 l_grad: 1.3003e+00 l_ssim: 9.2244e-01 l_x0: 1.2707e+00 
25-03-12 16:01:55.182 - INFO: <epoch:135, iter:  10,800> l_pix: 4.6390e+00 l_eps: 9.2297e-01 l_max: 3.4650e-01 l_grad: 1.3757e+00 l_ssim: 9.6332e-01 l_x0: 1.0305e+00 
25-03-12 16:02:14.560 - INFO: <epoch:137, iter:  10,900> l_pix: 4.6220e+00 l_eps: 9.4877e-01 l_max: 3.1635e-01 l_grad: 9.1005e-01 l_ssim: 1.1158e+00 l_x0: 1.3310e+00 
25-03-12 16:02:33.908 - INFO: <epoch:138, iter:  11,000> l_pix: 2.7556e+00 l_eps: 2.6071e-01 l_max: 2.4606e-01 l_grad: 7.2286e-01 l_ssim: 5.6020e-01 l_x0: 9.6579e-01 
25-03-12 16:02:53.211 - INFO: <epoch:139, iter:  11,100> l_pix: 4.4296e+00 l_eps: 7.8821e-01 l_max: 3.5883e-01 l_grad: 1.1902e+00 l_ssim: 1.0555e+00 l_x0: 1.0369e+00 
25-03-12 16:03:12.480 - INFO: <epoch:140, iter:  11,200> l_pix: 4.4003e+00 l_eps: 7.7533e-01 l_max: 3.4895e-01 l_grad: 1.0754e+00 l_ssim: 1.0737e+00 l_x0: 1.1270e+00 
25-03-12 16:03:31.838 - INFO: <epoch:142, iter:  11,300> l_pix: 4.9744e+00 l_eps: 1.8246e+00 l_max: 2.0278e-01 l_grad: 9.8930e-01 l_ssim: 7.9940e-01 l_x0: 1.1583e+00 
25-03-12 16:03:51.113 - INFO: <epoch:143, iter:  11,400> l_pix: 3.7502e+00 l_eps: 3.7637e-01 l_max: 3.0175e-01 l_grad: 1.0613e+00 l_ssim: 9.9928e-01 l_x0: 1.0114e+00 
25-03-12 16:04:10.458 - INFO: <epoch:144, iter:  11,500> l_pix: 4.6042e+00 l_eps: 8.2689e-01 l_max: 3.4400e-01 l_grad: 1.1366e+00 l_ssim: 1.0402e+00 l_x0: 1.2566e+00 
25-03-12 16:04:29.747 - INFO: <epoch:145, iter:  11,600> l_pix: 3.9552e+00 l_eps: 5.8992e-01 l_max: 2.4547e-01 l_grad: 1.0089e+00 l_ssim: 9.8650e-01 l_x0: 1.1243e+00 
25-03-12 16:04:49.086 - INFO: <epoch:147, iter:  11,700> l_pix: 6.2324e+00 l_eps: 2.5506e+00 l_max: 3.3893e-01 l_grad: 1.3761e+00 l_ssim: 8.1756e-01 l_x0: 1.1492e+00 
25-03-12 16:05:08.348 - INFO: <epoch:148, iter:  11,800> l_pix: 5.4094e+00 l_eps: 1.0181e+00 l_max: 4.1865e-01 l_grad: 1.4345e+00 l_ssim: 1.1027e+00 l_x0: 1.4355e+00 
25-03-12 16:05:27.611 - INFO: <epoch:149, iter:  11,900> l_pix: 4.1148e+00 l_eps: 6.5884e-01 l_max: 2.3285e-01 l_grad: 1.1635e+00 l_ssim: 8.8817e-01 l_x0: 1.1715e+00 
25-03-12 16:05:46.876 - INFO: <epoch:150, iter:  12,000> l_pix: 3.5210e+00 l_eps: 3.4386e-01 l_max: 2.5266e-01 l_grad: 8.7575e-01 l_ssim: 1.0541e+00 l_x0: 9.9462e-01 
25-03-12 16:05:55.448 - INFO: <epoch:150, iter:  12,000 Evaluation.>
25-03-12 16:05:55.448 - INFO: Saving models and training states.
25-03-12 16:05:55.992 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 16:05:55.992 - INFO: Saving models and training states.
25-03-12 16:05:56.602 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 16:06:16.008 - INFO: <epoch:152, iter:  12,100> l_pix: 3.9879e+00 l_eps: 7.5207e-01 l_max: 2.4416e-01 l_grad: 1.0379e+00 l_ssim: 8.3785e-01 l_x0: 1.1159e+00 
25-03-12 16:06:35.298 - INFO: <epoch:153, iter:  12,200> l_pix: 3.5381e+00 l_eps: 3.5275e-01 l_max: 2.6048e-01 l_grad: 9.7192e-01 l_ssim: 8.0841e-01 l_x0: 1.1445e+00 
25-03-12 16:06:54.566 - INFO: <epoch:154, iter:  12,300> l_pix: 3.2669e+00 l_eps: 5.2247e-01 l_max: 2.4793e-01 l_grad: 7.1655e-01 l_ssim: 6.7330e-01 l_x0: 1.1067e+00 
25-03-12 16:07:13.826 - INFO: <epoch:155, iter:  12,400> l_pix: 5.3511e+00 l_eps: 2.3209e+00 l_max: 2.6744e-01 l_grad: 8.2146e-01 l_ssim: 9.1108e-01 l_x0: 1.0302e+00 
25-03-12 16:07:33.181 - INFO: <epoch:157, iter:  12,500> l_pix: 3.7084e+00 l_eps: 3.1282e-01 l_max: 2.2680e-01 l_grad: 7.2827e-01 l_ssim: 1.1041e+00 l_x0: 1.3364e+00 
25-03-12 16:07:52.523 - INFO: <epoch:158, iter:  12,600> l_pix: 6.2851e+00 l_eps: 3.2794e+00 l_max: 2.3226e-01 l_grad: 8.9820e-01 l_ssim: 7.1028e-01 l_x0: 1.1650e+00 
25-03-12 16:08:11.812 - INFO: <epoch:159, iter:  12,700> l_pix: 3.8821e+00 l_eps: 6.4099e-01 l_max: 2.6303e-01 l_grad: 9.7229e-01 l_ssim: 9.7770e-01 l_x0: 1.0281e+00 
25-03-12 16:08:31.069 - INFO: <epoch:160, iter:  12,800> l_pix: 3.8853e+00 l_eps: 4.9261e-01 l_max: 2.8433e-01 l_grad: 8.0408e-01 l_ssim: 1.0282e+00 l_x0: 1.2761e+00 
25-03-12 16:08:50.412 - INFO: <epoch:162, iter:  12,900> l_pix: 5.6872e+00 l_eps: 2.3371e+00 l_max: 3.3984e-01 l_grad: 7.4107e-01 l_ssim: 1.0434e+00 l_x0: 1.2258e+00 
25-03-12 16:09:09.678 - INFO: <epoch:163, iter:  13,000> l_pix: 4.1101e+00 l_eps: 5.6745e-01 l_max: 2.8156e-01 l_grad: 1.1486e+00 l_ssim: 8.7942e-01 l_x0: 1.2331e+00 
25-03-12 16:09:28.929 - INFO: <epoch:164, iter:  13,100> l_pix: 1.0053e+01 l_eps: 6.1873e+00 l_max: 3.8170e-01 l_grad: 1.3425e+00 l_ssim: 1.1895e+00 l_x0: 9.5226e-01 
25-03-12 16:09:48.240 - INFO: <epoch:165, iter:  13,200> l_pix: 4.2845e+00 l_eps: 8.6549e-01 l_max: 2.9014e-01 l_grad: 1.1779e+00 l_ssim: 9.1417e-01 l_x0: 1.0368e+00 
25-03-12 16:10:07.590 - INFO: <epoch:167, iter:  13,300> l_pix: 3.7925e+00 l_eps: 4.6676e-01 l_max: 2.8051e-01 l_grad: 8.5996e-01 l_ssim: 1.0686e+00 l_x0: 1.1168e+00 
25-03-12 16:10:26.892 - INFO: <epoch:168, iter:  13,400> l_pix: 3.9919e+00 l_eps: 1.0888e+00 l_max: 2.3803e-01 l_grad: 8.4589e-01 l_ssim: 9.0988e-01 l_x0: 9.0931e-01 
25-03-12 16:10:46.189 - INFO: <epoch:169, iter:  13,500> l_pix: 3.6220e+00 l_eps: 3.7919e-01 l_max: 2.9463e-01 l_grad: 9.1642e-01 l_ssim: 9.0707e-01 l_x0: 1.1247e+00 
25-03-12 16:11:05.443 - INFO: <epoch:170, iter:  13,600> l_pix: 4.1284e+00 l_eps: 2.9311e-01 l_max: 2.9153e-01 l_grad: 1.2744e+00 l_ssim: 1.0203e+00 l_x0: 1.2490e+00 
25-03-12 16:11:24.832 - INFO: <epoch:172, iter:  13,700> l_pix: 4.7072e+00 l_eps: 6.7637e-01 l_max: 3.7928e-01 l_grad: 1.3248e+00 l_ssim: 1.1021e+00 l_x0: 1.2247e+00 
25-03-12 16:11:44.089 - INFO: <epoch:173, iter:  13,800> l_pix: 4.4134e+00 l_eps: 1.3324e+00 l_max: 2.6262e-01 l_grad: 9.8963e-01 l_ssim: 7.6349e-01 l_x0: 1.0652e+00 
25-03-12 16:12:03.357 - INFO: <epoch:174, iter:  13,900> l_pix: 4.5610e+00 l_eps: 8.5799e-01 l_max: 2.8736e-01 l_grad: 1.3662e+00 l_ssim: 8.6973e-01 l_x0: 1.1797e+00 
25-03-12 16:12:22.610 - INFO: <epoch:175, iter:  14,000> l_pix: 4.3593e+00 l_eps: 1.1672e+00 l_max: 2.5452e-01 l_grad: 8.0218e-01 l_ssim: 9.2460e-01 l_x0: 1.2108e+00 
25-03-12 16:12:31.154 - INFO: <epoch:175, iter:  14,000 Evaluation.>
25-03-12 16:12:31.154 - INFO: Saving models and training states.
25-03-12 16:12:31.681 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 16:12:31.681 - INFO: Saving models and training states.
25-03-12 16:12:32.214 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 16:12:51.553 - INFO: <epoch:177, iter:  14,100> l_pix: 3.1437e+00 l_eps: 3.0595e-01 l_max: 1.8853e-01 l_grad: 6.5400e-01 l_ssim: 7.9043e-01 l_x0: 1.2048e+00 
25-03-12 16:13:10.877 - INFO: <epoch:178, iter:  14,200> l_pix: 4.1065e+00 l_eps: 1.3287e+00 l_max: 2.4458e-01 l_grad: 7.4365e-01 l_ssim: 9.5752e-01 l_x0: 8.3196e-01 
25-03-12 16:13:30.154 - INFO: <epoch:179, iter:  14,300> l_pix: 4.2513e+00 l_eps: 9.1248e-01 l_max: 2.4552e-01 l_grad: 9.0154e-01 l_ssim: 1.0994e+00 l_x0: 1.0924e+00 
25-03-12 16:13:49.444 - INFO: <epoch:180, iter:  14,400> l_pix: 3.5525e+00 l_eps: 4.0896e-01 l_max: 2.1071e-01 l_grad: 9.4562e-01 l_ssim: 8.8406e-01 l_x0: 1.1031e+00 
25-03-12 16:14:08.802 - INFO: <epoch:182, iter:  14,500> l_pix: 3.7584e+00 l_eps: 4.8113e-01 l_max: 2.7487e-01 l_grad: 8.8394e-01 l_ssim: 8.7232e-01 l_x0: 1.2462e+00 
25-03-12 16:14:28.077 - INFO: <epoch:183, iter:  14,600> l_pix: 4.2169e+00 l_eps: 4.5582e-01 l_max: 2.9237e-01 l_grad: 1.0835e+00 l_ssim: 1.0525e+00 l_x0: 1.3327e+00 
25-03-12 16:14:47.369 - INFO: <epoch:184, iter:  14,700> l_pix: 2.9524e+00 l_eps: 2.4225e-01 l_max: 1.8340e-01 l_grad: 6.6613e-01 l_ssim: 7.6684e-01 l_x0: 1.0938e+00 
25-03-12 16:15:06.714 - INFO: <epoch:185, iter:  14,800> l_pix: 3.9694e+00 l_eps: 8.3353e-01 l_max: 2.5792e-01 l_grad: 1.0004e+00 l_ssim: 8.5841e-01 l_x0: 1.0192e+00 
25-03-12 16:15:26.099 - INFO: <epoch:187, iter:  14,900> l_pix: 4.0955e+00 l_eps: 2.5334e-01 l_max: 3.0605e-01 l_grad: 8.4607e-01 l_ssim: 1.0327e+00 l_x0: 1.6574e+00 
25-03-12 16:15:45.388 - INFO: <epoch:188, iter:  15,000> l_pix: 3.6841e+00 l_eps: 5.2951e-01 l_max: 2.4186e-01 l_grad: 8.5055e-01 l_ssim: 1.0185e+00 l_x0: 1.0437e+00 
25-03-12 16:16:04.666 - INFO: <epoch:189, iter:  15,100> l_pix: 5.6371e+00 l_eps: 2.5857e+00 l_max: 2.6324e-01 l_grad: 8.9579e-01 l_ssim: 7.6282e-01 l_x0: 1.1296e+00 
25-03-12 16:16:23.947 - INFO: <epoch:190, iter:  15,200> l_pix: 3.7109e+00 l_eps: 3.7791e-01 l_max: 3.1135e-01 l_grad: 1.0220e+00 l_ssim: 8.9602e-01 l_x0: 1.1037e+00 
25-03-12 16:16:43.353 - INFO: <epoch:192, iter:  15,300> l_pix: 1.0457e+01 l_eps: 6.6013e+00 l_max: 2.7986e-01 l_grad: 1.3644e+00 l_ssim: 9.6335e-01 l_x0: 1.2481e+00 
25-03-12 16:17:02.624 - INFO: <epoch:193, iter:  15,400> l_pix: 3.8309e+00 l_eps: 3.5588e-01 l_max: 2.3454e-01 l_grad: 1.1880e+00 l_ssim: 9.5099e-01 l_x0: 1.1015e+00 
25-03-12 16:17:21.898 - INFO: <epoch:194, iter:  15,500> l_pix: 3.5844e+00 l_eps: 6.1535e-01 l_max: 2.3277e-01 l_grad: 5.8279e-01 l_ssim: 8.3678e-01 l_x0: 1.3167e+00 
25-03-12 16:17:41.156 - INFO: <epoch:195, iter:  15,600> l_pix: 4.1426e+00 l_eps: 3.5872e-01 l_max: 3.6812e-01 l_grad: 1.3314e+00 l_ssim: 1.1189e+00 l_x0: 9.6541e-01 
25-03-12 16:18:00.528 - INFO: <epoch:197, iter:  15,700> l_pix: 4.4941e+00 l_eps: 8.6602e-01 l_max: 3.5838e-01 l_grad: 7.7599e-01 l_ssim: 1.1203e+00 l_x0: 1.3734e+00 
25-03-12 16:18:19.800 - INFO: <epoch:198, iter:  15,800> l_pix: 4.1120e+00 l_eps: 2.4781e-01 l_max: 3.0589e-01 l_grad: 1.2188e+00 l_ssim: 9.9966e-01 l_x0: 1.3398e+00 
25-03-12 16:18:39.139 - INFO: <epoch:199, iter:  15,900> l_pix: 3.6454e+00 l_eps: 6.4115e-01 l_max: 2.0955e-01 l_grad: 8.8721e-01 l_ssim: 8.6571e-01 l_x0: 1.0417e+00 
25-03-12 16:18:58.429 - INFO: <epoch:200, iter:  16,000> l_pix: 3.4638e+00 l_eps: 4.8605e-01 l_max: 2.2523e-01 l_grad: 6.3316e-01 l_ssim: 9.4091e-01 l_x0: 1.1784e+00 
25-03-12 16:19:06.970 - INFO: <epoch:200, iter:  16,000 Evaluation.>
25-03-12 16:19:06.970 - INFO: Saving models and training states.
25-03-12 16:19:07.512 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 16:19:07.512 - INFO: Saving models and training states.
25-03-12 16:19:08.019 - INFO: Saved model in [checkpoint/Finall_gen.pth] ...
25-03-12 16:19:08.043 - INFO: End of training.
